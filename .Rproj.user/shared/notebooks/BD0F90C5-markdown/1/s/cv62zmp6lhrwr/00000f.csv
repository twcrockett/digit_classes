"0","for model_name, model_func in model_functions.items():
    # Track metrics across folds
    fold_accuracies = []
    fold_precisions = []
    fold_recalls = []
    fold_times = []
    
    print(f""Evaluating best {model_name} model"")
    
    # Perform k-fold cross-validation
    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        
        start_time = time.time()
        y_pred = model_func(X_train, X_test, y_train, y_test)
        elapsed_time = time.time() - start_time
        fold_times.append(elapsed_time)
        
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True)
        precision = report['weighted avg']['precision']
        recall = report['weighted avg']['recall']
        
        # Store results for this fold
        fold_accuracies.append(accuracy)
        fold_precisions.append(precision)
        fold_recalls.append(recall)
        
        print(f""  Fold {fold_idx+1}/{skf.n_splits}: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, Time={elapsed_time:.2f}s"")
    
    # Compute average metrics across all folds
    mean_accuracy = np.mean(fold_accuracies)
    mean_precision = np.mean(fold_precisions)
    mean_recall = np.mean(fold_recalls)
    total_time = sum(fold_times)
    f1_score = 2 * (mean_precision * mean_recall) / (mean_precision + mean_recall)
    
    # Store results for this model
    result = {
        'model': model_name,
        'mean_accuracy': mean_accuracy,
        'mean_precision': mean_precision,
        'mean_recall': mean_recall,
        'f1_score': f1_score,
        'total_time': total_time,
    }
    
    # Add the best hyperparameters to the result
    best_config = best_configs[model_name]
    for param, value in best_config.items():
        if param not in ['mean_accuracy', 'mean_precision', 'mean_recall', 'f1_score', 'total_time', 'selection_score']:
            result[param] = value
    
    final_results.append(result)
    
    print(f""  Average: Accuracy={mean_accuracy:.4f}, Precision={mean_precision:.4f}, Recall={mean_recall:.4f}, F1={f1_score:.4f}, Time={total_time:.2f}s"")

"
"1","Evaluating best LogisticRegression model
"
"1","  Fold 1/5: Accuracy=0.9484, Precision=0.9483, Recall=0.9484, Time=1.52s
"
"1","  Fold 2/5: Accuracy=0.9382, Precision=0.9384, Recall=0.9382, Time=1.14s
"
"1","  Fold 3/5: Accuracy=0.9452, Precision=0.9451, Recall=0.9452, Time=1.19s
"
"1","  Fold 4/5: Accuracy=0.9387, Precision=0.9385, Recall=0.9387, Time=0.62s
"
"1","  Fold 5/5: Accuracy=0.9398, Precision=0.9404, Recall=0.9398, Time=0.55s
  Average: Accuracy=0.9420, Precision=0.9421, Recall=0.9420, F1=0.9421, Time=5.02s
Evaluating best SVD model
"
"2","Traceback (most recent call last):
  File ""<string>"", line 16, in <module>
  File ""<string>"", line 6, in <lambda>
  File ""<string>"", line 3, in SVD_residual
KeyError: 'n_components'
"
